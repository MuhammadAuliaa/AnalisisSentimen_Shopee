{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import HdpModel\n",
    "from gensim import corpora\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ulasan</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ulas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bahan aja warna navy nya beda</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kasih catat order warna kuning navy baca kirim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kecil</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>barang selamat terima kasih bahan celana nya s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>kecil</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>pesan cuna barang rusak coba konfirmasi tanggap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>karet pinggang nya kencang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>aja mahal sih hrg segitu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Ulasan  Sentimen\n",
       "0                                                 ulas         0\n",
       "1                                                  NaN         0\n",
       "2                        bahan aja warna navy nya beda         0\n",
       "3    kasih catat order warna kuning navy baca kirim...         0\n",
       "4                                                kecil         0\n",
       "..                                                 ...       ...\n",
       "990  barang selamat terima kasih bahan celana nya s...         0\n",
       "991                                              kecil         0\n",
       "992    pesan cuna barang rusak coba konfirmasi tanggap         0\n",
       "993                         karet pinggang nya kencang         0\n",
       "994                           aja mahal sih hrg segitu         0\n",
       "\n",
       "[995 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baca data\n",
    "df = pd.read_csv('../data/dataHasilPreprocessing/dataPreprocessing.csv')\n",
    "df['Sentimen'] = df['Sentimen'].map({'Positif': 1, 'Negatif': 0})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus duplikat dan nilai yang hilang\n",
    "df = df.drop_duplicates(subset=['Ulasan'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews = [review.lower().split() for review in df['Ulasan']]\n",
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "corpus = [dictionary.doc2bow(review) for review in tokenized_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_model = HdpModel(corpus, dictionary)\n",
    "num_topics = 5  # Misalnya, kita akan menggunakan 5 topik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendapatkan distribusi topik untuk setiap ulasan\n",
    "topic_distributions = [hdp_model[doc] for doc in corpus]\n",
    "\n",
    "# Mendapatkan bobot topik untuk setiap ulasan\n",
    "aspect_list = []\n",
    "for dist in topic_distributions:\n",
    "    aspect = max(dist, key=lambda x: x[1])[0]  # Ambil topik dengan bobot terbesar\n",
    "    aspect_list.append(aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambahkan atribut aspek ke dalam dataframe\n",
    "df['Aspect'] = aspect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model BERT\n",
    "model_name = 'indobenchmark/indobert-base-p1'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pra-pemrosesan data untuk BERT\n",
    "reviews = df['Ulasan'].tolist()\n",
    "labels = df['Sentimen'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# Tokenisasi data\n",
    "for review in reviews:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        review,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.concat(input_ids, axis=0)\n",
    "attention_masks = tf.concat(attention_masks, axis=0)\n",
    "labels = tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data menjadi train dan test sets\n",
    "train_indices, test_indices = train_test_split(range(len(input_ids)), test_size=0.2, random_state=42)\n",
    "train_indices = tf.convert_to_tensor(train_indices, dtype=tf.int32)\n",
    "test_indices = tf.convert_to_tensor(test_indices, dtype=tf.int32)\n",
    "\n",
    "train_input_ids = tf.gather(input_ids, train_indices)\n",
    "train_attention_masks = tf.gather(attention_masks, train_indices)\n",
    "train_labels = tf.gather(labels, train_indices)\n",
    "\n",
    "test_input_ids = tf.gather(input_ids, test_indices)\n",
    "test_attention_masks = tf.gather(attention_masks, test_indices)\n",
    "test_labels = tf.gather(labels, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurasi pelatihan\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "48/48 [==============================] - 22s 256ms/step - loss: 0.4959 - accuracy: 0.8399 - val_loss: 0.3688 - val_accuracy: 0.8789\n",
      "Epoch 2/15\n",
      "48/48 [==============================] - 11s 220ms/step - loss: 0.2676 - accuracy: 0.9021 - val_loss: 0.2907 - val_accuracy: 0.8842\n",
      "Epoch 3/15\n",
      "48/48 [==============================] - 11s 222ms/step - loss: 0.1453 - accuracy: 0.9484 - val_loss: 0.3349 - val_accuracy: 0.8526\n",
      "Epoch 4/15\n",
      "48/48 [==============================] - 11s 220ms/step - loss: 0.0809 - accuracy: 0.9775 - val_loss: 0.4428 - val_accuracy: 0.8684\n",
      "Epoch 5/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 0.0423 - accuracy: 0.9947 - val_loss: 0.5316 - val_accuracy: 0.8684\n",
      "Epoch 6/15\n",
      "48/48 [==============================] - 11s 223ms/step - loss: 0.0265 - accuracy: 0.9947 - val_loss: 0.5777 - val_accuracy: 0.8368\n",
      "Epoch 7/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 0.0312 - accuracy: 0.9934 - val_loss: 0.5688 - val_accuracy: 0.8737\n",
      "Epoch 8/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 0.0205 - accuracy: 0.9960 - val_loss: 0.5203 - val_accuracy: 0.8789\n",
      "Epoch 9/15\n",
      "48/48 [==============================] - 11s 220ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.6008 - val_accuracy: 0.8789\n",
      "Epoch 10/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.8737\n",
      "Epoch 11/15\n",
      "48/48 [==============================] - 11s 225ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.8684\n",
      "Epoch 12/15\n",
      "48/48 [==============================] - 11s 227ms/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 0.5964 - val_accuracy: 0.8789\n",
      "Epoch 13/15\n",
      "48/48 [==============================] - 11s 226ms/step - loss: 0.1090 - accuracy: 0.9709 - val_loss: 0.6082 - val_accuracy: 0.8316\n",
      "Epoch 14/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.5779 - val_accuracy: 0.8842\n",
      "Epoch 15/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.6604 - val_accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "# Latih model\n",
    "batch_size = 16\n",
    "epochs = 15\n",
    "\n",
    "history = model.fit(\n",
    "    [train_input_ids, train_attention_masks],\n",
    "    train_labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=([test_input_ids, test_attention_masks], test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 133ms/step - loss: 0.6604 - accuracy: 0.8684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6604195237159729, 0.8684210777282715]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluasi model\n",
    "model.evaluate([test_input_ids, test_attention_masks], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Ulasan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>ulas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>bahan aja warna navy nya beda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>kasih catat order warna kuning navy baca kirim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>kecil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>tau layan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>cocok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>barang selamat terima kasih bahan celana nya s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>pesan cuna barang rusak coba konfirmasi tanggap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>karet pinggang nya kencang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>aja mahal sih hrg segitu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>946 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Aspect  Sentimen                                             Ulasan\n",
       "0        78         0                                               ulas\n",
       "2        41         0                      bahan aja warna navy nya beda\n",
       "3        82         0  kasih catat order warna kuning navy baca kirim...\n",
       "4         4         0                                              kecil\n",
       "5        71         0                                          tau layan\n",
       "..      ...       ...                                                ...\n",
       "989     115         0                                              cocok\n",
       "990      71         0  barang selamat terima kasih bahan celana nya s...\n",
       "992      20         0    pesan cuna barang rusak coba konfirmasi tanggap\n",
       "993     139         0                         karet pinggang nya kencang\n",
       "994     118         0                           aja mahal sih hrg segitu\n",
       "\n",
       "[946 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan aspek dalam dataframe\n",
    "df_aspect = pd.DataFrame({'Aspect': aspect_list, 'Sentimen': df['Sentimen'], 'Ulasan': df['Ulasan']})\n",
    "df_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 133ms/step - loss: 0.6604 - accuracy: 0.8684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6604195237159729, 0.8684210777282715]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluasi model sebelum menggunakan HDP\n",
    "model.evaluate([test_input_ids, test_attention_masks], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 134ms/step\n",
      "Classification Report Sebelum Menggunakan HDP:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.55      0.56        29\n",
      "           1       0.92      0.93      0.92       161\n",
      "\n",
      "    accuracy                           0.87       190\n",
      "   macro avg       0.75      0.74      0.74       190\n",
      "weighted avg       0.87      0.87      0.87       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Buat prediksi untuk data sebelum menggunakan HDP\n",
    "test_predictions_before_hdp = model.predict([test_input_ids, test_attention_masks])\n",
    "predicted_labels_before_hdp = tf.argmax(test_predictions_before_hdp.logits, axis=1)\n",
    "\n",
    "# Tampilkan laporan klasifikasi sebelum menggunakan HDP\n",
    "classification_rep_before_hdp = classification_report(test_labels, predicted_labels_before_hdp)\n",
    "print(\"Classification Report Sebelum Menggunakan HDP:\")\n",
    "print(classification_rep_before_hdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latih model setelah menggunakan HDP\n",
    "train_input_ids_after_hdp = train_input_ids\n",
    "train_attention_masks_after_hdp = train_attention_masks\n",
    "train_labels_after_hdp = train_labels\n",
    "\n",
    "test_input_ids_after_hdp = test_input_ids\n",
    "test_attention_masks_after_hdp = test_attention_masks\n",
    "test_labels_after_hdp = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "48/48 [==============================] - 11s 224ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8684\n",
      "Epoch 2/15\n",
      "48/48 [==============================] - 11s 224ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8684\n",
      "Epoch 3/15\n",
      "48/48 [==============================] - 11s 222ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7273 - val_accuracy: 0.8684\n",
      "Epoch 4/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7725 - val_accuracy: 0.8632\n",
      "Epoch 5/15\n",
      "48/48 [==============================] - 11s 220ms/step - loss: 9.2317e-04 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.8579\n",
      "Epoch 6/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 8.4998e-04 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.8684\n",
      "Epoch 7/15\n",
      "48/48 [==============================] - 11s 220ms/step - loss: 7.7885e-04 - accuracy: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.8684\n",
      "Epoch 8/15\n",
      "48/48 [==============================] - 10s 215ms/step - loss: 9.0333e-04 - accuracy: 1.0000 - val_loss: 0.7946 - val_accuracy: 0.8737\n",
      "Epoch 9/15\n",
      "48/48 [==============================] - 10s 215ms/step - loss: 6.7408e-04 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.8632\n",
      "Epoch 10/15\n",
      "48/48 [==============================] - 11s 220ms/step - loss: 6.1742e-04 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.8632\n",
      "Epoch 11/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 5.7326e-04 - accuracy: 1.0000 - val_loss: 0.8286 - val_accuracy: 0.8632\n",
      "Epoch 12/15\n",
      "48/48 [==============================] - 11s 224ms/step - loss: 5.4518e-04 - accuracy: 1.0000 - val_loss: 0.8376 - val_accuracy: 0.8684\n",
      "Epoch 13/15\n",
      "48/48 [==============================] - 11s 228ms/step - loss: 5.1069e-04 - accuracy: 1.0000 - val_loss: 0.8462 - val_accuracy: 0.8684\n",
      "Epoch 14/15\n",
      "48/48 [==============================] - 11s 231ms/step - loss: 4.8122e-04 - accuracy: 1.0000 - val_loss: 0.8537 - val_accuracy: 0.8684\n",
      "Epoch 15/15\n",
      "48/48 [==============================] - 11s 228ms/step - loss: 4.5590e-04 - accuracy: 1.0000 - val_loss: 0.8600 - val_accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "# Latih model\n",
    "history_after_hdp = model.fit(\n",
    "    [train_input_ids_after_hdp, train_attention_masks_after_hdp],\n",
    "    train_labels_after_hdp,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=([test_input_ids_after_hdp, test_attention_masks_after_hdp], test_labels_after_hdp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 136ms/step - loss: 0.8600 - accuracy: 0.8684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8599599003791809, 0.8684210777282715]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluasi model setelah menggunakan HDP\n",
    "model.evaluate([test_input_ids_after_hdp, test_attention_masks_after_hdp], test_labels_after_hdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 134ms/step\n",
      "Classification Report Sesudah Menggunakan HDP:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.55      0.56        29\n",
      "           1       0.92      0.93      0.92       161\n",
      "\n",
      "    accuracy                           0.87       190\n",
      "   macro avg       0.75      0.74      0.74       190\n",
      "weighted avg       0.87      0.87      0.87       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Buat prediksi untuk data setelah menggunakan HDP\n",
    "test_predictions_after_hdp = model.predict([test_input_ids_after_hdp, test_attention_masks_after_hdp])\n",
    "predicted_labels_after_hdp = tf.argmax(test_predictions_after_hdp.logits, axis=1)\n",
    "\n",
    "# Tampilkan laporan klasifikasi setelah menggunakan HDP\n",
    "classification_rep_after_hdp = classification_report(test_labels_after_hdp, predicted_labels_after_hdp)\n",
    "print(\"Classification Report Sesudah Menggunakan HDP:\")\n",
    "print(classification_rep_after_hdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_load",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
