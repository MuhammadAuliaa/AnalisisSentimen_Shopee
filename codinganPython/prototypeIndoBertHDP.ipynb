{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import HdpModel\n",
    "from gensim import corpora\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ulasan</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ulas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bahan aja warna navy nya beda</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kasih catat order warna kuning navy baca kirim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kecil</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>barang selamat terima kasih bahan celana nya s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>kecil</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>pesan cuna barang rusak coba konfirmasi tanggap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>karet pinggang nya kencang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>aja mahal sih hrg segitu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Ulasan  Sentimen\n",
       "0                                                 ulas         0\n",
       "1                                                  NaN         0\n",
       "2                        bahan aja warna navy nya beda         0\n",
       "3    kasih catat order warna kuning navy baca kirim...         0\n",
       "4                                                kecil         0\n",
       "..                                                 ...       ...\n",
       "990  barang selamat terima kasih bahan celana nya s...         0\n",
       "991                                              kecil         0\n",
       "992    pesan cuna barang rusak coba konfirmasi tanggap         0\n",
       "993                         karet pinggang nya kencang         0\n",
       "994                           aja mahal sih hrg segitu         0\n",
       "\n",
       "[995 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baca data\n",
    "df = pd.read_csv('../data/dataHasilPreprocessing/hasilPreprocessing1.csv')\n",
    "df['Sentimen'] = df['Sentimen'].map({'Positif': 1, 'Negatif': 0})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus duplikat dan nilai yang hilang\n",
    "df = df.drop_duplicates(subset=['Ulasan'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews = [review.lower().split() for review in df['Ulasan']]\n",
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "corpus = [dictionary.doc2bow(review) for review in tokenized_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_model = HdpModel(corpus, dictionary)\n",
    "num_topics = 5  # Misalnya, kita akan menggunakan 5 topik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendapatkan distribusi topik untuk setiap ulasan\n",
    "topic_distributions = [hdp_model[doc] for doc in corpus]\n",
    "\n",
    "# Mendapatkan bobot topik untuk setiap ulasan\n",
    "aspect_list = []\n",
    "for dist in topic_distributions:\n",
    "    aspect = max(dist, key=lambda x: x[1])[0]  # Ambil topik dengan bobot terbesar\n",
    "    aspect_list.append(aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambahkan atribut aspek ke dalam dataframe\n",
    "df['Aspect'] = aspect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model BERT\n",
    "model_name = 'indobenchmark/indobert-base-p1'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pra-pemrosesan data untuk BERT\n",
    "reviews = df['Ulasan'].tolist()\n",
    "labels = df['Sentimen'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# Tokenisasi data\n",
    "for review in reviews:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        review,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.concat(input_ids, axis=0)\n",
    "attention_masks = tf.concat(attention_masks, axis=0)\n",
    "labels = tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data menjadi train dan test sets\n",
    "train_indices, test_indices = train_test_split(range(len(input_ids)), test_size=0.2, random_state=42)\n",
    "train_indices = tf.convert_to_tensor(train_indices, dtype=tf.int32)\n",
    "test_indices = tf.convert_to_tensor(test_indices, dtype=tf.int32)\n",
    "\n",
    "train_input_ids = tf.gather(input_ids, train_indices)\n",
    "train_attention_masks = tf.gather(attention_masks, train_indices)\n",
    "train_labels = tf.gather(labels, train_indices)\n",
    "\n",
    "test_input_ids = tf.gather(input_ids, test_indices)\n",
    "test_attention_masks = tf.gather(attention_masks, test_indices)\n",
    "test_labels = tf.gather(labels, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurasi pelatihan\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "48/48 [==============================] - 26s 265ms/step - loss: 0.5276 - accuracy: 0.8309 - val_loss: 0.3113 - val_accuracy: 0.8789\n",
      "Epoch 2/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 0.3087 - accuracy: 0.8692 - val_loss: 0.2870 - val_accuracy: 0.8895\n",
      "Epoch 3/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 0.1819 - accuracy: 0.9419 - val_loss: 0.2914 - val_accuracy: 0.8684\n",
      "Epoch 4/15\n",
      "48/48 [==============================] - 11s 223ms/step - loss: 0.0882 - accuracy: 0.9775 - val_loss: 0.3411 - val_accuracy: 0.8842\n",
      "Epoch 5/15\n",
      "48/48 [==============================] - 11s 223ms/step - loss: 0.0493 - accuracy: 0.9894 - val_loss: 0.4205 - val_accuracy: 0.8895\n",
      "Epoch 6/15\n",
      "48/48 [==============================] - 11s 224ms/step - loss: 0.0495 - accuracy: 0.9881 - val_loss: 0.3668 - val_accuracy: 0.9053\n",
      "Epoch 7/15\n",
      "48/48 [==============================] - 11s 222ms/step - loss: 0.0763 - accuracy: 0.9749 - val_loss: 0.4348 - val_accuracy: 0.8789\n",
      "Epoch 8/15\n",
      "48/48 [==============================] - 11s 221ms/step - loss: 0.0337 - accuracy: 0.9947 - val_loss: 0.4491 - val_accuracy: 0.9053\n",
      "Epoch 9/15\n",
      "48/48 [==============================] - 11s 226ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.4544 - val_accuracy: 0.8842\n",
      "Epoch 10/15\n",
      "48/48 [==============================] - 11s 225ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.5204 - val_accuracy: 0.8684\n",
      "Epoch 11/15\n",
      "48/48 [==============================] - 11s 224ms/step - loss: 0.0360 - accuracy: 0.9894 - val_loss: 0.4228 - val_accuracy: 0.8842\n",
      "Epoch 12/15\n",
      "48/48 [==============================] - 11s 224ms/step - loss: 0.0193 - accuracy: 0.9960 - val_loss: 0.5814 - val_accuracy: 0.8842\n",
      "Epoch 13/15\n",
      "48/48 [==============================] - 11s 224ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.6113 - val_accuracy: 0.8737\n",
      "Epoch 14/15\n",
      "48/48 [==============================] - 11s 222ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6404 - val_accuracy: 0.8789\n",
      "Epoch 15/15\n",
      "48/48 [==============================] - 11s 220ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8789\n"
     ]
    }
   ],
   "source": [
    "# Latih model\n",
    "batch_size = 16\n",
    "epochs = 15\n",
    "\n",
    "history = model.fit(\n",
    "    [train_input_ids, train_attention_masks],\n",
    "    train_labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=([test_input_ids, test_attention_masks], test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 134ms/step - loss: 0.6652 - accuracy: 0.8789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6652217507362366, 0.878947377204895]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluasi model\n",
    "model.evaluate([test_input_ids, test_attention_masks], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 130ms/step\n"
     ]
    }
   ],
   "source": [
    "# Buat prediksi\n",
    "test_predictions = model.predict([test_input_ids, test_attention_masks])\n",
    "predicted_labels = tf.argmax(test_predictions.logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Ulasan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>ulas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>bahan aja warna navy nya beda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>kasih catat order warna kuning navy baca kirim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>kecil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>tau layan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>cocok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>barang selamat terima kasih bahan celana nya s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>pesan cuna barang rusak coba konfirmasi tanggap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>karet pinggang nya kencang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>aja mahal sih hrg segitu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>947 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Aspect  Sentimen                                             Ulasan\n",
       "0        76         0                                               ulas\n",
       "2       147         0                      bahan aja warna navy nya beda\n",
       "3       135         0  kasih catat order warna kuning navy baca kirim...\n",
       "4       104         0                                              kecil\n",
       "5        41         0                                          tau layan\n",
       "..      ...       ...                                                ...\n",
       "989      61         0                                              cocok\n",
       "990      58         0  barang selamat terima kasih bahan celana nya s...\n",
       "992      99         0    pesan cuna barang rusak coba konfirmasi tanggap\n",
       "993      81         0                         karet pinggang nya kencang\n",
       "994     130         0                           aja mahal sih hrg segitu\n",
       "\n",
       "[947 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan aspek dalam dataframe\n",
    "df_aspect = pd.DataFrame({'Aspect': aspect_list, 'Sentimen': df['Sentimen'], 'Ulasan': df['Ulasan']})\n",
    "df_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.35      0.41        23\n",
      "           1       0.91      0.95      0.93       167\n",
      "\n",
      "    accuracy                           0.88       190\n",
      "   macro avg       0.71      0.65      0.67       190\n",
      "weighted avg       0.86      0.88      0.87       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tampilkan laporan klasifikasi\n",
    "classification_rep = classification_report(test_labels, predicted_labels)\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_load",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
