{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytypo\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puan Maharani Menambahkan Kata Pro Rakyat Dala...</td>\n",
       "      <td>Puan Maharani Tambahkan ‚ÄúPro Rakyat‚Äù di Akhir ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bawa Langsung Lansia ke Rumah Lansia Atmabrata</td>\n",
       "      <td>Teman2 terkasih, kalau kenal/tahu lansia yg ti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pesan Singkat Perihal Biaya Asuransi Kirim Bar...</td>\n",
       "      <td>Barang yang dikirim melalui jasa Jalur (JNE), ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ribuan Warga Tasik jalan kaki menuju Jakarta u...</td>\n",
       "      <td>Jalan kaki menuju Jakarta untuk Aksi Kedaulata...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breaking News: Megawati Mengundurkan Diri Dari...</td>\n",
       "      <td>Disaat_umat_ISLAM_lagi_gencar_menyerang_Moncon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>Kanada Sudah Terbebas dari Covid-19</td>\n",
       "      <td>CANADA is now Covid free! i hope philippines n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>Gedung Putih Dibanjiri Massa Pro Ahok, dan men...</td>\n",
       "      <td>BERITA GEMPAR HARI INI!!! PENOLAKAN FPI SAMPAI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>Anies Pilih Pembinaan Daripada Cabut KJP Untuk...</td>\n",
       "      <td>Saya tak pernah menggariskan pencabutan (hak) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>Metallica Indonesia Raya</td>\n",
       "      <td>METALLICA‚Ä¶ Indonesia Raya‚Ä¶.üáÆüá©üáÆüá©üáÆüá©üáÆüá©</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3806</th>\n",
       "      <td>Aplikasi Body Temperature Diary bisa mengukur ...</td>\n",
       "      <td>Wahh‚Ä¶ternyata kita bisa mengukur suhu tubuh ki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3807 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  judul  \\\n",
       "0     Puan Maharani Menambahkan Kata Pro Rakyat Dala...   \n",
       "1        Bawa Langsung Lansia ke Rumah Lansia Atmabrata   \n",
       "2     Pesan Singkat Perihal Biaya Asuransi Kirim Bar...   \n",
       "3     Ribuan Warga Tasik jalan kaki menuju Jakarta u...   \n",
       "4     Breaking News: Megawati Mengundurkan Diri Dari...   \n",
       "...                                                 ...   \n",
       "3802                Kanada Sudah Terbebas dari Covid-19   \n",
       "3803  Gedung Putih Dibanjiri Massa Pro Ahok, dan men...   \n",
       "3804  Anies Pilih Pembinaan Daripada Cabut KJP Untuk...   \n",
       "3805                           Metallica Indonesia Raya   \n",
       "3806  Aplikasi Body Temperature Diary bisa mengukur ...   \n",
       "\n",
       "                                                 narasi  label  \n",
       "0     Puan Maharani Tambahkan ‚ÄúPro Rakyat‚Äù di Akhir ...      1  \n",
       "1     Teman2 terkasih, kalau kenal/tahu lansia yg ti...      0  \n",
       "2     Barang yang dikirim melalui jasa Jalur (JNE), ...      1  \n",
       "3     Jalan kaki menuju Jakarta untuk Aksi Kedaulata...      1  \n",
       "4     Disaat_umat_ISLAM_lagi_gencar_menyerang_Moncon...      1  \n",
       "...                                                 ...    ...  \n",
       "3802  CANADA is now Covid free! i hope philippines n...      1  \n",
       "3803  BERITA GEMPAR HARI INI!!! PENOLAKAN FPI SAMPAI...      1  \n",
       "3804  Saya tak pernah menggariskan pencabutan (hak) ...      1  \n",
       "3805                METALLICA‚Ä¶ Indonesia Raya‚Ä¶.üáÆüá©üáÆüá©üáÆüá©üáÆüá©      1  \n",
       "3806  Wahh‚Ä¶ternyata kita bisa mengukur suhu tubuh ki...      1  \n",
       "\n",
       "[3807 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data/hapusData/train.csv\")\n",
    "# df_train['Sentimen'] = df_train['Sentimen'].map({'Positif': 1, 'Negatif': 0})\n",
    "df_train = df_train[['judul', 'narasi', 'label']]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "judul     0\n",
      "narasi    0\n",
      "label     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(judul     0\n",
       " narasi    0\n",
       " label     0\n",
       " dtype: int64,\n",
       " (3807, 3))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.isna().sum())\n",
    "df_train.dropna(inplace = True)\n",
    "df_train.isna().sum() , df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>: PSSI Pecat Ratu Tisha Sebagai Sekjen</td>\n",
       "      <td>Enggak usah dijelaskan, itu tidak benar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>Polisi Tangkap Perekayasa Chat Hoax Kapolri da...</td>\n",
       "      <td>Polisi Tangkap Perekayasa Chat Hoax Kapolri da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>AM Hendropriyono Dirawat di Singapur</td>\n",
       "      <td>MUBAHALAH HABIB RS MANJUR !!\\nAM HENDROPRIYONO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>Siswa kejang-kejang saat bermain game online d...</td>\n",
       "      <td>Sebuah video memperlihatkan seorang siswa terl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>surat kabar luar negeri memberitakan jokowi tu...</td>\n",
       "      <td>Horeeee akhirnya‚Ä¶.surat kabar luar negeri memb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  judul  \\\n",
       "1410             : PSSI Pecat Ratu Tisha Sebagai Sekjen   \n",
       "2378  Polisi Tangkap Perekayasa Chat Hoax Kapolri da...   \n",
       "796                AM Hendropriyono Dirawat di Singapur   \n",
       "2845  Siswa kejang-kejang saat bermain game online d...   \n",
       "1651  surat kabar luar negeri memberitakan jokowi tu...   \n",
       "\n",
       "                                                 narasi  label  \n",
       "1410            Enggak usah dijelaskan, itu tidak benar      1  \n",
       "2378  Polisi Tangkap Perekayasa Chat Hoax Kapolri da...      0  \n",
       "796   MUBAHALAH HABIB RS MANJUR !!\\nAM HENDROPRIYONO...      1  \n",
       "2845  Sebuah video memperlihatkan seorang siswa terl...      1  \n",
       "1651  Horeeee akhirnya‚Ä¶.surat kabar luar negeri memb...      1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.sample(frac=1,random_state = 0)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text) : \n",
    "\n",
    "  text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[#]+|[^A-Za-z0-9]+\"\n",
    "  text_cleaning_hash = \"#[A-Za-z0-9]+\" \n",
    "  text_cleaning_num = \"(^|\\W)\\d+\"\n",
    "\n",
    "  text = re.sub(text_cleaning_hash, \" \", text).strip()\n",
    "  text = re.sub(text_cleaning_num, \" \", text).strip()\n",
    "  text = re.sub(text_cleaning_re, \" \", text).strip()\n",
    "  \n",
    "  text = text.strip()\n",
    "\n",
    "  out = []\n",
    "  for word in text.split() :\n",
    "    # try : \n",
    "    #   out.append(word.replace(word, slang[word]))\n",
    "    # except Exception as e : \n",
    "    out.append(word)\n",
    "      \n",
    "  return pytypo.correct_sentence(\" \".join(out).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeEmoji(text):\n",
    "    allchars = [str for str in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>narasi</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>PSSI Pecat Ratu Tisha Sebagai Sekjen</td>\n",
       "      <td>Enggak usah dijelaskan itu tidak benar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>Polisi Tangkap Perekayasa Chat Hoax Kapolri da...</td>\n",
       "      <td>Polisi Tangkap Perekayasa Chat Hoax Kapolri da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>AM Hendropriyono Dirawat di Singapur</td>\n",
       "      <td>MUBAHALAH HABIB RS MANJUR AM HENDROPRIYONO ATI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>Siswa kejang kejang saat bermain game online d...</td>\n",
       "      <td>Sebuah video memperlihatkan seorang siswa terl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>surat kabar luar negeri memberitakan jokowi tu...</td>\n",
       "      <td>Horee akhirnya surat kabar luar negeri memberi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>Terakhir yang diketahui adalah terhadap Sam Lo...</td>\n",
       "      <td>Ternyata penggunaan ular untuk interogasi oran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>Penemuan Sabu di Dalam Nanas Terjadi di Indonesia</td>\n",
       "      <td>Nanas illegal isinya sabu2 yg dikemas Nanas bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>Foto Hati hati kalo kita beli sepatu Logo palu...</td>\n",
       "      <td>Hati hati kalo kita beli sepatu Logo palu arit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>Ang Tjoen Min Berada Di Balik Organisasi Teror...</td>\n",
       "      <td>DENSUS NEO CAKRA BIRAWA Ang Tjoeng Ming ipar J...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>Syiah menyerang Saudi pada musim haji</td>\n",
       "      <td>Dapet berita dari koran lama edisi pnri tentan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3807 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  judul  \\\n",
       "1410               PSSI Pecat Ratu Tisha Sebagai Sekjen   \n",
       "2378  Polisi Tangkap Perekayasa Chat Hoax Kapolri da...   \n",
       "796                AM Hendropriyono Dirawat di Singapur   \n",
       "2845  Siswa kejang kejang saat bermain game online d...   \n",
       "1651  surat kabar luar negeri memberitakan jokowi tu...   \n",
       "...                                                 ...   \n",
       "835   Terakhir yang diketahui adalah terhadap Sam Lo...   \n",
       "3264  Penemuan Sabu di Dalam Nanas Terjadi di Indonesia   \n",
       "1653  Foto Hati hati kalo kita beli sepatu Logo palu...   \n",
       "2607  Ang Tjoen Min Berada Di Balik Organisasi Teror...   \n",
       "2732              Syiah menyerang Saudi pada musim haji   \n",
       "\n",
       "                                                 narasi  label  \n",
       "1410             Enggak usah dijelaskan itu tidak benar      1  \n",
       "2378  Polisi Tangkap Perekayasa Chat Hoax Kapolri da...      0  \n",
       "796   MUBAHALAH HABIB RS MANJUR AM HENDROPRIYONO ATI...      1  \n",
       "2845  Sebuah video memperlihatkan seorang siswa terl...      1  \n",
       "1651  Horee akhirnya surat kabar luar negeri memberi...      1  \n",
       "...                                                 ...    ...  \n",
       "835   Ternyata penggunaan ular untuk interogasi oran...      1  \n",
       "3264  Nanas illegal isinya sabu2 yg dikemas Nanas bu...      1  \n",
       "1653  Hati hati kalo kita beli sepatu Logo palu arit...      1  \n",
       "2607  DENSUS NEO CAKRA BIRAWA Ang Tjoeng Ming ipar J...      1  \n",
       "2732  Dapet berita dari koran lama edisi pnri tentan...      1  \n",
       "\n",
       "[3807 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm= {\" dgn \" : \" dengan \", ' seller ': ' penjual ',' service ':' pelayanan ', ' tp ':' tapi ', ' recommended ':' rekomendasi ', ' kren ':' keren ', ' kereen ':' keren ', ' mantab ': ' keren ',' matching ':' sesuai ','happy':' senang ','original': 'asli ','ori':'asli ', \"trusted\" : \"terpercaya\", \"angjaaaassss\":\"keren\", \" gue \": \" saya \", \"bgmn \":\" bagaimana \", ' tdk':' tidak ', ' blum ':' belum ', 'mantaaaaaaaappp':' bagus ', 'mantaaap':'bagus ', ' josss ':' bagus ', ' thanks ': ' terima kasih ', 'fast':' cepat ', ' dg ':' dengan ', 'trims':' terima kasih ', 'brg':' barang ', 'gx':' tidak ', ' dgn ':' dengan ', ' recommended':' rekomen ', 'recomend':' rekomen ', 'good':' bagus ', \" dgn \" : \" dengan \", \" gue \": \" saya \", \" dgn \":\" dengan \", \"bgmn \":\" bagaimana \", ' tdk':' tidak ', \n",
    "' blum ':' belum ', \"quality\":\"kualitas\", 'baguss':'bagus', 'overall' : 'akhirnya', 'mantaaaaaaaappp':' bagus ', ' josss ':' bagus ', ' thanks ': ' terima kasih ', 'fast':' cepat ', \n",
    " 'trims':' terima kasih ', 'brg':' barang ', 'gx':' tidak ', ' dgn ':' dengan ', ' real ': ' asli ', ' bnb ': ' baru ' ,\n",
    "' recommended':' rekomen ', 'recomend':' rekomen ', 'good':'bagus',\n",
    "'eksis ':'ada ', 'beenilai ':'bernilai ', ' dg ':' dengan ', ' ori ':' asli ', ' setting ':' atur ', \" free \":\" gratis \",\n",
    "' yg ':' yang ', 't4 ':'tempat', ' awat ':' awet', ' mantep ':' bagus ', 'mantapp':'bagus', \n",
    "'kl ':'kalo', ' k ':' ke ', 'plg ':'pulang ', 'ajah ':'aja ', 'bgt':'banget', 'lbh ':'lebih', 'ayem':'tenang','dsana ':'disana ', 'lg':' lagi',\n",
    "'pas ':'saat ', ' bnib ': ' baru ', \n",
    "' nggak ':' tidak ', 'karna ':'karena ', 'utk ':'untuk ',\n",
    "' dn ':' dan ', ' mlht ':' melihat ', ' pd ':' pada ', 'mndngr ':'mendengar ', 'crita':'cerita', ' dpt ':' dapat ', ' mksh ':' terima kasih ', ' sellerrrr':' penjual', 'ori ':'asli ', ' new ':' baru ',\n",
    "'sejrh':'sejarah', 'mnmbh ':'menambah ', 'sayapun':'saya', 'thn ':'tahun ', 'good':'bagus', ' awettt':' awet',\n",
    "'halu ':'halusinasi ', ' nyantai ':' santai ', 'plus ':'dan ',\n",
    "' ayang ':' sayang ', ' Rekomendded ':' direkomendasikan ', ' now ': ' sekarang ', 'slalu ':'selalu ', 'photo ': 'foto ', 'slah ':'salah ', 'krn':'karena', ' ga ':' tidak ', 'ok ':'oke ', ' meski':' mesti', ' para ':'parah', ' nawarin':' menawari', 'socmed':'sosial media',\n",
    "' sya ':' saya ', 'siip':'bagus', ' bny ':' banyak ', ' tdk ':' tidak ', ' byk ':' banyak ', \n",
    "' pool ':' sekali ', \" pgn \":\" ingin \", \" gue \":\" saya \", \" bgmn \":\" bagaimana \", \" ga \":\" tidak \", \n",
    "\" gak \":\" tidak \", \" dr \":\" dari \", \" yg \":\" yang \", \" lu \":\" kamu \", \" sya \":\" saya \", \n",
    "\" lancarrr \":\" lancar \", \" kayak \":\" seperti \", \" ngawur \":\" sembarangan \", \" k \":\" ke \", \n",
    "\" luasss \":\" luas \", \" sy \":\" saya \", \" thn \":\" tahun \", \" males \":\" malas \",\n",
    "\" tgl \":\" tanggal \", \" lg \":\" lagi \", \" bgt \":\" banget \",' gua ':' saya ', '\\n':' ', ' tpi ':' tapi ', ' standar ':' biasa ', ' standart ': ' biasa ', ' sdh ':' sudah ', ' n ':' dan ', ' gk ': ' tidak ', ' mengecwakan ':' mengecewakan ', ' d ':' di ', ' approved':' setuju', 'ademmmm ':'adem ', ' g ':' tidak ', ' gak ':' tidak ', ' cpt ':' cepat '}\n",
    "\n",
    "def normalisasi(text):\n",
    "  for i in norm:\n",
    "    text = text.replace(i, norm[i])\n",
    "  return text\n",
    "\n",
    "def clean(text):\n",
    "  text = text.strip()\n",
    "  text = text.lower()\n",
    "  text = re.sub(r'[^a-zA-Z]+', ' ', text)\n",
    "  return text\n",
    "\n",
    "def tokenisasi(text):\n",
    "    return text.split() \n",
    "    \n",
    "def stopword(text):\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.casefold() not in stop_words]\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_load",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
