{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sisi Koding\n",
    "1. Rapihin preprocessingnya\n",
    "2. Jalankan HDP untuk liat top 30 nya (baru setelah ini bisa kabarin aku dulu biar aku liat list topiknya dan aku bisa tentuin aspeknya (kelarin HDP)\n",
    "3. Topik yang aku pilih akan menjadi tolak ukur untuk Analisa sentimennya. Sekaligus merapihan data-data yang akan di mapping ke aspek tersebut \n",
    "mau, baik, bahan, warna, kain.\n",
    "warna ukuran bahan = \n",
    "\n",
    "4. Analisa sentiment berbasis aspeknya menggunakan SVM dan Indobert -> hasil akhir mirip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interface :\n",
    "svm & indobert -> harga berapa positif & negatif, bahan berapa positif & negatif, warna berapa positif & negatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "program bisa diakses tanpa coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 menu : bisa masukin link\n",
    "\n",
    "- crawling data (sentimen negatif 50 positif 50 (rate1-3 50%, rate 4-5 50%))\n",
    "- segmentasi kain (lembut, halus, dll)\n",
    "- barchart kosongin jika gada sesuai dengan aspek (hasil ulasan tidak mengandung tema bahan, warna, dan kain!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models import HdpModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Muhammad Ade\n",
      "[nltk_data]     Aulia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Muhammad Ade\n",
      "[nltk_data]     Aulia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Muhammad Ade\n",
      "[nltk_data]     Aulia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kata-Kata Berdasarkan Segmentasi:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segmentasi</th>\n",
       "      <th>Kata</th>\n",
       "      <th>Bobot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bahan</td>\n",
       "      <td>rapih</td>\n",
       "      <td>0.005432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kualitas</td>\n",
       "      <td>bagus</td>\n",
       "      <td>0.005824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>other</td>\n",
       "      <td>cuman</td>\n",
       "      <td>0.007922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>other</td>\n",
       "      <td>mustard</td>\n",
       "      <td>0.007787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>other</td>\n",
       "      <td>tambah</td>\n",
       "      <td>0.006914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>other</td>\n",
       "      <td>nyampenya</td>\n",
       "      <td>0.003929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>pengiriman</td>\n",
       "      <td>kilo</td>\n",
       "      <td>0.006292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>pengiriman</td>\n",
       "      <td>super</td>\n",
       "      <td>0.004660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>warna</td>\n",
       "      <td>warna</td>\n",
       "      <td>0.005471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>warna</td>\n",
       "      <td>pink</td>\n",
       "      <td>0.003916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Segmentasi       Kata     Bobot\n",
       "0        bahan      rapih  0.005432\n",
       "1     kualitas      bagus  0.005824\n",
       "24       other      cuman  0.007922\n",
       "64       other    mustard  0.007787\n",
       "81       other     tambah  0.006914\n",
       "..         ...        ...       ...\n",
       "67       other  nyampenya  0.003929\n",
       "92  pengiriman       kilo  0.006292\n",
       "93  pengiriman      super  0.004660\n",
       "95       warna      warna  0.005471\n",
       "94       warna       pink  0.003916\n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unduh stopwords dan wordnet jika belum diunduh\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Baca data ulasan dari file CSV\n",
    "df = pd.read_csv(\"data/dataHasilPreprocessing/dataPreprocessing.csv\")\n",
    "\n",
    "# Mengisi nilai NaN dengan string kosong\n",
    "df['Ulasan'] = df['Ulasan'].fillna('')\n",
    "\n",
    "# Inisialisasi stop words dan lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Fungsi preprocessing\n",
    "def preprocess(text):\n",
    "    # Tokenisasi\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Hapus stop words dan tanda baca, lakukan lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return tokens\n",
    "\n",
    "# Preprocessing data ulasan\n",
    "df['processed'] = df['Ulasan'].apply(preprocess)\n",
    "\n",
    "# Buat dictionary dan corpus\n",
    "dictionary = corpora.Dictionary(df['processed'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['processed']]\n",
    "\n",
    "# Latih model HDP\n",
    "hdp = HdpModel(corpus, dictionary)\n",
    "\n",
    "# Ekstrak topik dan kata kunci\n",
    "top_topics = hdp.show_topics(num_topics=10, num_words=10, formatted=False)\n",
    "top_words = []\n",
    "\n",
    "# Daftar kata kunci untuk setiap segmentasi\n",
    "segmentation_keywords = {\n",
    "    'bahan': ['tipis', 'tebal', 'lembut', 'keras', 'kasar', 'rapih', 'rapi', 'pendek', 'adem', 'nyaman', 'jahit', 'halus', 'gerah', 'relaxing', 'baju', 'model', 'celana', 'nama', 'transparan', 'badan', 'sayap'],\n",
    "    'pengiriman': ['cepat', 'lambat', 'lelet', 'ontime', 'terlambat', 'instan', 'kurir', 'ekspektasi', 'semangat', 'kilogram', 'packingan', 'super', 'gampang', 'kilo', 'ekspedisi', 'online', 'kirim', 'diiket', 'angkat'],\n",
    "    'kualitas': ['rusak', 'sesuai', 'bagus', 'jelek', 'berkualitas', 'keringat', 'sobek', 'aneh', 'foto', 'gambar', 'keren', 'mantap', 'kecil', 'label', 'ngetat', 'ketat', 'pict', 'fashion', 'bolong', 'style', 'sederhana'],\n",
    "    'warna': ['cerah', 'pudar', 'gelap', 'putih', 'hitam', 'warna', 'biru', 'soft', 'navy', 'pink'],\n",
    "    'harga': ['murah', 'mahal', 'terjangkau', 'ekonomis', 'premium', 'uang', 'duit', 'refund', 'promo', 'promonya'],\n",
    "    'respon': ['ragu', 'tidak puas', 'kurang', 'positif', 'negatif', 'astaga', 'tengkyuu', 'emang', 'tanggap', 'nyoba', 'suka', 'worth', 'haha', 'tolong', 'banget', 'balas', 'thanks', 'thank', 'aduh']\n",
    "}\n",
    "\n",
    "# Fungsi untuk menentukan segmentasi\n",
    "def categorize_word(word):\n",
    "    for segment, keywords in segmentation_keywords.items():\n",
    "        if word in keywords:\n",
    "            return segment\n",
    "    return 'other'\n",
    "\n",
    "# Mengelompokkan kata berdasarkan segmentasi\n",
    "segmentation_words = []\n",
    "\n",
    "for i, topic in top_topics:\n",
    "    for word, weight in topic:\n",
    "        segment = categorize_word(word)\n",
    "        segmentation_words.append({'Segmentasi': segment, 'Kata': word, 'Bobot': weight})\n",
    "\n",
    "# Buat DataFrame untuk kata\n",
    "# a-kata berdasarkan segmentasi\n",
    "segmentation_words_df = pd.DataFrame(segmentation_words)\n",
    "segmentation_summary_df = segmentation_words_df.groupby(['Segmentasi', 'Kata']).agg({'Bobot': 'max'}).reset_index()\n",
    "segmentation_summary_df = segmentation_summary_df.sort_values(by=['Segmentasi', 'Bobot'], ascending=[True, False])\n",
    "\n",
    "print(\"\\nKata-Kata Berdasarkan Segmentasi:\")\n",
    "segmentation_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_load",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
