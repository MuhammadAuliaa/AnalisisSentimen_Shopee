{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ulasan</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sangat kecewa dengan pelayanan restoran ini.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pelayanannya cukup bagus, tapi makanannya bias...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Makanan di restoran ini enak sekali!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pelayanan hotelnya sangat buruk.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kamar hotel sangat nyaman dan bersih.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pengalaman belanja yang mengecewakan.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stafnya ramah dan membantu.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Makanan terasa hambar.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lokasi hotel sangat strategis.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tempatnya terlalu ramai dan tidak nyaman.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pelayanan staf hotel sangat ramah dan sopan.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Menu makanan terbatas dan tidak bervariasi.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Restoran ini memiliki suasana yang nyaman.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pelayanan kasir yang lambat dan tidak efisien.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tempatnya bersih dan nyaman.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Harga terlalu mahal untuk kualitas makanan yan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tempatnya sangat ramai dan tidak nyaman.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kualitas pelayanan yang baik.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Suasana restoran tidak menyenangkan.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pelayanannya cepat dan efisien.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Makanan di sini terlalu pedas untuk selera saya.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Suasana hotel yang tenang dan nyaman.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Restoran ini kurang bersih.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tempatnya luas dan nyaman.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Makanan tidak sesuai dengan ekspektasi saya.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ulasan  label\n",
       "0        Sangat kecewa dengan pelayanan restoran ini.      0\n",
       "1   Pelayanannya cukup bagus, tapi makanannya bias...      1\n",
       "2                Makanan di restoran ini enak sekali!      2\n",
       "3                    Pelayanan hotelnya sangat buruk.      0\n",
       "4               Kamar hotel sangat nyaman dan bersih.      2\n",
       "5               Pengalaman belanja yang mengecewakan.      0\n",
       "6                         Stafnya ramah dan membantu.      2\n",
       "7                              Makanan terasa hambar.      0\n",
       "8                      Lokasi hotel sangat strategis.      2\n",
       "9           Tempatnya terlalu ramai dan tidak nyaman.      0\n",
       "10       Pelayanan staf hotel sangat ramah dan sopan.      2\n",
       "11        Menu makanan terbatas dan tidak bervariasi.      0\n",
       "12         Restoran ini memiliki suasana yang nyaman.      2\n",
       "13     Pelayanan kasir yang lambat dan tidak efisien.      0\n",
       "14                       Tempatnya bersih dan nyaman.      2\n",
       "15  Harga terlalu mahal untuk kualitas makanan yan...      0\n",
       "16           Tempatnya sangat ramai dan tidak nyaman.      0\n",
       "17                      Kualitas pelayanan yang baik.      2\n",
       "18               Suasana restoran tidak menyenangkan.      0\n",
       "19                    Pelayanannya cepat dan efisien.      2\n",
       "20   Makanan di sini terlalu pedas untuk selera saya.      0\n",
       "21              Suasana hotel yang tenang dan nyaman.      2\n",
       "22                        Restoran ini kurang bersih.      0\n",
       "23                         Tempatnya luas dan nyaman.      2\n",
       "24       Makanan tidak sesuai dengan ekspektasi saya.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data dummy 50 baris ulasan dan label sentimen\n",
    "data = {\n",
    "    'ulasan': [\n",
    "        \"Sangat kecewa dengan pelayanan restoran ini.\",\n",
    "        \"Pelayanannya cukup bagus, tapi makanannya biasa saja.\",\n",
    "        \"Makanan di restoran ini enak sekali!\",\n",
    "        \"Pelayanan hotelnya sangat buruk.\",\n",
    "        \"Kamar hotel sangat nyaman dan bersih.\",\n",
    "        \"Pengalaman belanja yang mengecewakan.\",\n",
    "        \"Stafnya ramah dan membantu.\",\n",
    "        \"Makanan terasa hambar.\",\n",
    "        \"Lokasi hotel sangat strategis.\",\n",
    "        \"Tempatnya terlalu ramai dan tidak nyaman.\",\n",
    "        \"Pelayanan staf hotel sangat ramah dan sopan.\",\n",
    "        \"Menu makanan terbatas dan tidak bervariasi.\",\n",
    "        \"Restoran ini memiliki suasana yang nyaman.\",\n",
    "        \"Pelayanan kasir yang lambat dan tidak efisien.\",\n",
    "        \"Tempatnya bersih dan nyaman.\",\n",
    "        \"Harga terlalu mahal untuk kualitas makanan yang diberikan.\",\n",
    "        \"Tempatnya sangat ramai dan tidak nyaman.\",\n",
    "        \"Kualitas pelayanan yang baik.\",\n",
    "        \"Suasana restoran tidak menyenangkan.\",\n",
    "        \"Pelayanannya cepat dan efisien.\",\n",
    "        \"Makanan di sini terlalu pedas untuk selera saya.\",\n",
    "        \"Suasana hotel yang tenang dan nyaman.\",\n",
    "        \"Restoran ini kurang bersih.\",\n",
    "        \"Tempatnya luas dan nyaman.\",\n",
    "        \"Makanan tidak sesuai dengan ekspektasi saya.\"\n",
    "    ],\n",
    "    'label': [\n",
    "        0, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2,\n",
    "        0, 2, 0, 2, 0\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Membuat DataFrame dari data dummy\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Menampilkan 5 baris pertama DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9bdde5736347c0855175a227f662a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/656M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Muhammad Ade Aulia\\.cache\\huggingface\\hub\\models--indobenchmark--indobert-base-p1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load IndoBERT model and tokenizer\n",
    "model_name = 'indobenchmark/indobert-base-p1'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['ulasan'].tolist()\n",
    "labels = df['label'].tolist()  # Pastikan label Anda adalah numerik: 0 untuk negatif, 1 untuk netral, 2 untuk positif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenize data\n",
    "max_length = 128  # Panjang maksimum input ke model\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for review in reviews:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        review,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.concat(input_ids, axis=0)\n",
    "attention_masks = tf.concat(attention_masks, axis=0)\n",
    "labels = tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_indices, test_indices = train_test_split(range(len(input_ids)), test_size=0.2, random_state=42)\n",
    "\n",
    "# Konversi indeks numpy ke tensor TensorFlow\n",
    "train_indices = tf.convert_to_tensor(train_indices, dtype=tf.int32)\n",
    "test_indices = tf.convert_to_tensor(test_indices, dtype=tf.int32)\n",
    "\n",
    "# Gunakan indeks tensor untuk mengindeks data pelatihan dan pengujian\n",
    "train_input_ids = tf.gather(input_ids, train_indices)\n",
    "train_attention_masks = tf.gather(attention_masks, train_indices)\n",
    "train_labels = tf.gather(labels, train_indices)\n",
    "\n",
    "test_input_ids = tf.gather(input_ids, test_indices)\n",
    "test_attention_masks = tf.gather(attention_masks, test_indices)\n",
    "test_labels = tf.gather(labels, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training configuration\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2/2 [==============================] - 16s 2s/step - loss: 1.5950 - accuracy: 0.2000 - val_loss: 1.1411 - val_accuracy: 0.6000\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.0819 - accuracy: 0.6500 - val_loss: 0.8720 - val_accuracy: 0.6000\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8003 - accuracy: 0.8500 - val_loss: 0.7955 - val_accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "\n",
    "history = model.fit(\n",
    "    [train_input_ids, train_attention_masks],\n",
    "    train_labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=([test_input_ids, test_attention_masks], test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 308ms/step - loss: 0.7955 - accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7955330014228821, 0.6000000238418579]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate([test_input_ids, test_attention_masks], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.30      0.50      0.38         5\n",
      "weighted avg       0.36      0.60      0.45         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Muhammad Ade Aulia\\miniconda3\\envs\\gpu_load\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "test_predictions = model.predict([test_input_ids, test_attention_masks])\n",
    "predicted_labels = tf.argmax(test_predictions.logits, axis=1)\n",
    "\n",
    "# Show classification report\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_load",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
